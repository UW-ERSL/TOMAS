{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import scipy.io\n",
    "from typing import Tuple, List\n",
    "from enum import Enum, auto\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "sys.path.insert(0, '../vae')\n",
    "sys.path.insert(0, '../fluid_TO')\n",
    "sys.path.insert(0, '../dataset')\n",
    "import dataset.supershape as supershape\n",
    "import yaml\n",
    "import material_constants\n",
    "import fluid_mesher\n",
    "import fluid_bcs\n",
    "import fluid_material\n",
    "import fluid_fe\n",
    "import projection\n",
    "import neural_network\n",
    "import loss\n",
    "import utils\n",
    "import plot\n",
    "import opt_constraints\n",
    "import torch.optim as optim\n",
    "\n",
    "import vae.network as vae_network\n",
    "import vae.data_preprocess as vae_data_prep\n",
    "import vae.train_vae as train_vae\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Config File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config_diffuser.yaml\", \"r\") as file:\n",
    "    config_data = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fluid Mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounding_box = fluid_mesher.BoundingBox(x_min= config_data[\"BOUNDING_BOX\"][\"x_min\"],\n",
    "                                    x_max= config_data[\"BOUNDING_BOX\"][\"x_max\"],\n",
    "                                    y_min= config_data[\"BOUNDING_BOX\"][\"y_min\"],\n",
    "                                    y_max= config_data[\"BOUNDING_BOX\"][\"y_max\"])\n",
    "\n",
    "fluid_mesh = fluid_mesher.fluid_mesher(nelx = config_data[\"MESH\"][\"nelx\"],\n",
    "                                        nely = config_data[\"MESH\"][\"nely\"], \n",
    "                                        bounding_box=bounding_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boundary Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_velocity = config_data[\"BOUNDARY_CONDITIONS\"][\"char_velocity\"]\n",
    "fluid_bc = fluid_bcs.get_dirichlet_bc_and_fixed_dofs(\n",
    "    fluid_mesh, char_velocity, fluid_bcs.FluidSampleProblems[\n",
    "      config_data[\"BOUNDARY_CONDITIONS\"][\"example\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fluid Material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluid_mat_constants = material_constants.MaterialConstants(\n",
    "                                        kinematic_viscosity =  config_data[\n",
    "                                          \"MATERIAL_CONSTANTS\"][\n",
    "                                          \"kinematic_viscosity\"])\n",
    "                                            \n",
    "fluid_material = fluid_material.FluidMaterial(fluid_mesh.elem_dx,\n",
    "            fluid_mesh.elem_dy,\n",
    "            fluid_mat_constants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fluid Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluid_solver = fluid_fe.FluidSolver(fluid_mesh, fluid_bc,\n",
    "                                    fixture_const = \n",
    "                                    config_data[\"BOUNDARY_CONDITIONS\"]\n",
    "                                    [\"fixture_const\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourier_map = projection.FourierMap(fluid_mesh,\n",
    "  fourier_map_activation = ( projection.FourierActivation\n",
    "                            [config_data[\"FOURIER_MAP_PARAMS\"]\n",
    "                              [\"fourier_map_activation\"]]),\n",
    "  num_fourier_terms = config_data[\"FOURIER_MAP_PARAMS\"][\n",
    "                                      \"num_fourier_terms\"],\n",
    "  max_radius = config_data[\"FOURIER_MAP_PARAMS\"][\"max_radius\"],\n",
    "  min_radius = config_data[\"FOURIER_MAP_PARAMS\"][\"min_radius\"])\n",
    "\n",
    "symmetry_activation_x_axis = projection.SymmetryActivation.SYM_X_AXIS_ON\n",
    "symmetry_activation_y_axis = projection.SymmetryActivation.SYM_Y_AXIS_OFF\n",
    "\n",
    "constraint_type = opt_constraints.ConstraintType[config_data[\"OPTIMIZATION\"]\n",
    "                                                   [\"constraint_type\"]]\n",
    "nn_settings = neural_network.NeuralNetworkParameters(input_dim = 2*config_data[\"FOURIER_MAP_PARAMS\"]\n",
    "                                                      [\"num_fourier_terms\"],\n",
    "                                                      output_dim = config_data[\"NEURAL_NETWORK_PARAMS\"]\n",
    "                                                      [\"output_dim\"],\n",
    "                                                      num_layers = config_data[\"NEURAL_NETWORK_PARAMS\"]\n",
    "                                                      [\"num_layers\"],\n",
    "                                                      num_neurons_per_layer=config_data[\"NEURAL_NETWORK_PARAMS\"]\n",
    "                                                      [\"num_neurons_per_layer\"])\n",
    "\n",
    "neural_net = neural_network.TopOptNet(nn_params=nn_settings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"../vae\"\n",
    "file_name = \"vae_net.pt\"\n",
    "file_path = os.path.join(folder_path, file_name)\n",
    "with open(\"vae_config.yaml\", \"r\") as file:\n",
    "  vae_config_data = yaml.safe_load(file)\n",
    "vae_yaml = vae_config_data['NETWORK']\n",
    "vae_yaml = vae_config_data['NETWORK']\n",
    "vae_params = vae_network.VAE_Params(input_dim=12,\n",
    "                                encoder_hidden_dim=vae_yaml['encoder_hidden_dim'],\n",
    "                                latent_dim=vae_yaml['latent_dim'],\n",
    "                                decoder_hidden_dim=vae_yaml['decoder_hidden_dim'])\n",
    "vae_net = vae_network.VariationalAutoencoder(vae_params=vae_params)\n",
    "vae_net.encoder.is_training = False\n",
    "vae_net.load_state_dict(torch.load(file_path))\n",
    "vae_net.eval()\n",
    "nomalization = torch.load('../vae/nomalization.pt')\n",
    "max_feature = nomalization['max_feature']\n",
    "min_feature = nomalization['min_feature']\n",
    "print(\"Loading VAE\")\n",
    "normalization_types = [vae_data_prep.NomalizationType.LINEAR] * 8 + [vae_data_prep.NomalizationType.LOG] * 2 + [vae_data_prep.NomalizationType.LINEAR] * 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_projected_coordinates( fluid_sym_map, res: int)->torch.Tensor:\n",
    "  \"\"\"\n",
    "  Calculates the projected coordinates of fluid elements based on the\n",
    "  specified resolution, reflection and fourier map.\n",
    "  \n",
    "  Args:\n",
    "    res: Resolution parameter indicating the desired resolution in the sampled points.\n",
    "  \n",
    "  Returns:\n",
    "    fluid_xy_f: Tensor of size (num_elems, 2) representing the projected coordinates\n",
    "                of fluid elements.\n",
    "  \"\"\"\n",
    "  if (res == 1):\n",
    "    fluid_xy = torch.tensor(fluid_solver.mesh.elem_centers, \n",
    "                        requires_grad=True).double() \n",
    "    \n",
    "  else:\n",
    "    elem_centers = utils.generate_points_in_domain(fluid_mesher.nelx,\n",
    "                                    fluid_mesher.nely,\n",
    "                                    fluid_mesher.elem_dx,\n",
    "                                    fluid_mesher.elem_dy, \n",
    "                                    fluid_mesher.num_dim,\n",
    "                                    res)\n",
    "    fluid_xy = torch.tensor(elem_centers, \n",
    "                          requires_grad=True).double() \n",
    "  \n",
    "  fluid_xy_r, fluid_signs_reflection = projection.apply_reflection(fluid_xy,\n",
    "                                                                  symmetry_activation_y_axis,\n",
    "                                                                  symmetry_activation_x_axis,\n",
    "                                                                  fluid_sym_map)\n",
    "  \n",
    "  \n",
    "  if(fourier_map.fourier_map_activation == projection.FourierActivation.FOURIER_ON):\n",
    "    fluid_xy_f = fourier_map.apply_fourier_map(fluid_xy_r)\n",
    "  \n",
    "  return fluid_xy_f, fluid_signs_reflection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer(Enum):\n",
    "  ADAM = auto()\n",
    "  LBFGS = auto()\n",
    "  \n",
    "class GradClipActivation(Enum):\n",
    "  GRAD_CLIP_ON = auto()\n",
    "  GRAD_CLIP_OFF = auto()\n",
    "\n",
    "@dataclass\n",
    "class OptimizationSettings:\n",
    "  plot_interval: int\n",
    "  lr: float\n",
    "  num_epochs: int\n",
    "  method : int\n",
    "  grad_clip_activation: int\n",
    "  grad_clip_norm: float\n",
    "\n",
    "@dataclass \n",
    "class OptimizationInitials:\n",
    "  J0 : float\n",
    "  constraints : np.ndarray\n",
    "\n",
    "def optimize_design(opt_params: OptimizationSettings, loss_type:loss.LossTypes,\n",
    "                    loss_params:loss.AugmentedLagrangianParameters,\n",
    "                    opt_initials:OptimizationInitials,\n",
    "                    constraint_type: opt_constraints.ConstraintType, sym_params: projection.SymParams,\n",
    "                     desired_vol_frac:float, desired_perimeter: float, perim_scale = 2.):\n",
    "  \"\"\"\n",
    "  Optimize the design using the specified optimization parameters.\n",
    "\n",
    "  Args:\n",
    "      opt_params: Object representing the optimization settings.\n",
    "      loss_type: Enum representing the type of loss function to be used.\n",
    "      loss_params: Parameters for the augmented Lagrangian loss function.\n",
    "      opt_initials: Initial values for optimization parameters.\n",
    "      penalty_constants: Constants for the penalization.\n",
    "\n",
    "  Returns:\n",
    "      convergence_history: Dictionary containing lists of convergence values for each epoch.\n",
    "\n",
    "  \"\"\"\n",
    "  epoch = 0\n",
    "  convergence_history = {'epoch':[], 'perimeter':[], 'fluid_loss':[]}\n",
    "  \n",
    "  fluid_xy_f, fluid_signs_reflection = calculate_projected_coordinates(sym_params, res = 1.)\n",
    "  \n",
    "  if(opt_params.method == Optimizer.ADAM):\n",
    "      print('Adam working')\n",
    "      optimizer = optim.Adam(neural_net.parameters(), amsgrad=True, \n",
    "                              lr=opt_params.lr)  \n",
    "      \n",
    "  else:\n",
    "      print('LBFGS working')\n",
    "      optimizer = optim.LBFGS(neural_net.parameters(),\n",
    "                                    line_search_fn = 'strong_wolfe')\n",
    "        \n",
    "  def loss_wrapper( eps = 1e-6)-> Tuple[torch.Tensor, torch.Tensor, List, torch.Tensor,\n",
    "                              supershape.SuperShapes]:\n",
    "    \"\"\"\n",
    "    Calculates the loss and related parameters for the optimization process.\n",
    "    While data generation the fluid has density 1. and solid has 0, \n",
    "    but while getting the calculating the area it gives solid area.\n",
    "    Therefore the decoder gives the supershape's solid area and we substract it from 1.\n",
    "    to get the fluid volume fraction.\n",
    "\n",
    "    Returns:\n",
    "        net_loss: Tensor of size (1,) representing the combined loss value.\n",
    "        fluid_loss: Tensor of size (1,) representing the fluid loss value.\n",
    "        constraints: List of size (num_constraints,) constraint values. Currently it only contains fluid\n",
    "                    volume constraint.\n",
    "        fluid_vol_frac: Tensor of size (num_elems) and representing the fluid volume fraction.\n",
    "        mstr_params: Object containing arrays of number num_geometric_params\n",
    "                      where each array is of size (num_elems)\n",
    "                      representing the renormalized geometric parameters\n",
    "                      of the microstructures.\n",
    "  \"\"\"\n",
    "    optimizer.zero_grad()\n",
    "    latent_space, theta = neural_net(fluid_xy_f)\n",
    "    theta = torch.einsum('i,i->i', theta, fluid_signs_reflection['X'])\n",
    "    theta = torch.einsum('i,i->i', theta, fluid_signs_reflection['Y'])\n",
    "    decoded_latent_pt = vae_net.decoder(latent_space)\n",
    "    vae_output_renormalized = vae_data_prep.stack_vae_output(decoded_latent_pt, max_feature, min_feature, normalization_types)\n",
    "\n",
    "    if(constraint_type == opt_constraints.ConstraintType.VOLUME):\n",
    "      constraint_field = vae_output_renormalized[:, vae_data_prep.VAE_Fields.shape_area.value]\n",
    "    elif(constraint_type == opt_constraints.ConstraintType.PERIMETER):\n",
    "      constraint_field = fluid_solver.mesh.elem_dx*perim_scale*vae_output_renormalized[:, vae_data_prep.VAE_Fields.shape_perim.value]\n",
    "\n",
    "    C_00 = vae_output_renormalized[:, vae_data_prep.VAE_Fields.homog_c00.value] + eps\n",
    "    C_11 = vae_output_renormalized[:, vae_data_prep.VAE_Fields.homog_c11.value] + eps\n",
    "    mstr_data = vae_output_renormalized[:, :vae_data_prep.VAE_Fields.homog_c00.value].clone().detach().numpy()\n",
    "    mstr_params  = supershape.SuperShapes(mstr_data[:, 0], mstr_data[:, 1], mstr_data[:, 2], mstr_data[:, 3],\n",
    "                   mstr_data[:, 4], mstr_data[:, 5], mstr_data[:, 6], mstr_data[:, 7])\n",
    "    \n",
    "    fluid_loss, velocity_pressure_field = fluid_solver.fluid_objective_function( fluid_material, C_00, C_11, theta)\n",
    "    \n",
    "    field_cons_value = opt_constraints.constraint_function(constraint_type, constraint_field, desired_vol_frac, desired_perimeter) \n",
    "    if(epoch == 0 or epoch == 20):\n",
    "      opt_initials.J0 = (fluid_loss.item()) \n",
    "      \n",
    "  \n",
    "    opt_params.constraints = [field_cons_value]\n",
    "    net_loss = loss.combined_loss(\n",
    "      objective = fluid_loss/opt_initials.J0,              \n",
    "      constraints = opt_params.constraints,\n",
    "      loss_type = loss_type,\n",
    "      loss_params = loss_params,\n",
    "      epoch = epoch)\n",
    "    return (net_loss, fluid_loss, opt_params.constraints, constraint_field,\n",
    "            mstr_params, C_00, C_11, theta)\n",
    "  \n",
    "  \n",
    "  def closure() -> torch.Tensor:\n",
    "    \"\"\"\n",
    "      Closure function for the optimizer.\n",
    "  \n",
    "      This function performs a forward pass to calculate the total loss,\n",
    "      backward pass to compute gradients, and applies gradient clipping.\n",
    "      It returns the total loss.\n",
    "  \n",
    "      Returns:\n",
    "          net_loss: Tensor of size (1,)representing the total loss.\n",
    "    \"\"\"\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    (net_loss, fluid_loss, constraint, constraint_field, mstr_params,\n",
    "    C_00, C_11, theta)= loss_wrapper()\n",
    "    net_loss.backward(retain_graph = True)\n",
    "    \n",
    "    torch.nn.utils.clip_grad_norm_(neural_net.parameters(),\n",
    "                                    opt_params.grad_clip_norm)\n",
    "    return net_loss \n",
    "  \n",
    "  \n",
    "  for epoch in range(opt_params.num_epochs):\n",
    "    net_loss = closure()\n",
    "    if(opt_params.method == 'adam'):\n",
    "        \n",
    "      optimizer.step()\n",
    "        \n",
    "    else:\n",
    "\n",
    "      optimizer.step(closure)\n",
    "      \n",
    "    loss.update_loss_parameters(epoch, loss_type, loss_params, opt_params.constraints)  \n",
    "    (net_loss, fluid_loss, constraint, constraint_field,\n",
    "      mstr_params, C_00, C_11, theta) = loss_wrapper()\n",
    "    net_loss.backward(retain_graph = True)\n",
    "    convergence_history['epoch'].append(epoch)\n",
    "    convergence_history['perimeter'].append(torch.sum(constraint_field).item())\n",
    "    convergence_history['fluid_loss'].append(fluid_loss.item())\n",
    "    \n",
    "    status = \"Iter {:3d} J: {:.2E}; perimeter : {:.2F} \"\\\n",
    "      .format(epoch, fluid_loss.item(), torch.sum(constraint_field).item())\n",
    "    print(status)\n",
    "    \n",
    "    if(epoch % opt_params.plot_interval == 0):\n",
    "\n",
    "      theta = theta.clone().detach().numpy()\n",
    "      plot.plot_microstructures_in_macro_mesh(mstr_params,\n",
    "                                              theta,\n",
    "                                              fluid_solver.mesh.nelx,\n",
    "                                              fluid_solver.mesh.nely, \n",
    "                                              epoch)\n",
    "  \n",
    "  \n",
    "  return convergence_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sym_params = projection.SymParams(sym_x_axis_mid_pt = 0.5*config_data[\"BOUNDING_BOX\"][\"y_max\"],\n",
    "                                  sym_y_axis_mid_pt = 0.5*config_data[\"BOUNDING_BOX\"][\"x_max\"])\n",
    "\n",
    "num_constraints = config_data[\"OPTIMIZATION\"][\"num_constraints\"]\n",
    "desired_vol_frac = config_data[\"OPTIMIZATION\"][\"desired_vol_frac\"]\n",
    "desired_perimeter = config_data[\"OPTIMIZATION\"][\"desired_perimeter\"]\n",
    "\n",
    "loss_type = loss.LossTypes[config_data[\"LOSS\"][\"method\"]]\n",
    "\n",
    "\n",
    "loss_params = loss.PenaltyLossParameters(\n",
    "              alpha0 = config_data[\"LOSS\"][\"alpha0\"],\n",
    "              del_alpha = config_data[\"LOSS\"][\"del_alpha\"])\n",
    "\n",
    "opt_initials = OptimizationInitials( \n",
    "                J0 = config_data[\"OPTIMIZATION\"][\"init_objective\"], \n",
    "  constraints = np.zeros((num_constraints)))\n",
    "\n",
    "opt_params = OptimizationSettings(\n",
    "              plot_interval =  config_data[\"OPTIMIZATION\"][\"plot_interval\"],\n",
    "              lr = config_data[\"OPTIMIZATION\"][\"learning_rate\"],\n",
    "              num_epochs= config_data[\"OPTIMIZATION\"][\"num_epochs\"], \n",
    "              method = Optimizer[config_data[\"OPTIMIZATION\"][\"method\"]],\n",
    "              grad_clip_activation = GradClipActivation[\n",
    "                                      config_data[\"OPTIMIZATION\"]\n",
    "                                      [\"grad_clip_activation\"]],\n",
    "              grad_clip_norm = config_data[\"OPTIMIZATION\"]\n",
    "                                [\"grad_clip_norm\"]\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "gpu_status = utils.Gpu.OVERRIDE\n",
    "convg_history = optimize_design( opt_params, loss_type, loss_params, opt_initials, constraint_type, sym_params, desired_vol_frac, desired_perimeter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('pyML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "4602012142f164ad64901f41ac734ff17cd932e5bfd3346820f6d7f371034b4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
